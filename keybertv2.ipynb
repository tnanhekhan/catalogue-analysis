{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from keybert import KeyBERT"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data/courses.csv')\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "print(torch.version.cuda)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "kw_model = KeyBERT()\n",
    "\n",
    "\n",
    "def extract_keywords(course_description, n_gram):\n",
    "    if isinstance(course_description, str) and course_description not in ['-', '']:\n",
    "        keywords = kw_model.extract_keywords(course_description, stop_words='english', top_n=30, use_mmr=True,\n",
    "                                             keyphrase_ngram_range=(n_gram, n_gram))\n",
    "        return [kw[0] for kw in keywords]\n",
    "    return []  \n",
    "\n",
    "\n",
    "for course in df.columns[1:]: \n",
    "    df[f'{course}_keywords'] = df[course].apply(lambda x: extract_keywords(x, 1))\n",
    "    df[f'{course}_2word_phrases'] = df[course].apply(lambda x: extract_keywords(x, 2))\n",
    "    df[f'{course}_3word_phrases'] = df[course].apply(lambda x: extract_keywords(x, 3))\n",
    "\n",
    "print(\"Updated DataFrame with keywords and phrases:\")\n",
    "print(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "df.columns",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "courses = [\n",
    "    'Software Architecture',\n",
    "    'Software Testing',\n",
    "    'Requirements Engineering',\n",
    "    'Preparation Masterproject Software Engineering',\n",
    "    'Software Process',\n",
    "    'Software Construction',\n",
    "    'Masterproject Software Engineering',\n",
    "    'Software Evolution',\n",
    "    'Software Architecture (VU)',\n",
    "    'Software Specification, Verification and Testing',\n",
    "    'Embedded Software and Systems',\n",
    "    'DevOps and Cloud-based Software',\n",
    "    'Model-based Design of Cyber-physical Systems'\n",
    "]\n",
    "\n",
    "\n",
    "def count_phrases(text, phrases):\n",
    "    text = text.lower()\n",
    "    count = 0\n",
    "    for phrase in phrases:\n",
    "        count += text.count(phrase.lower())\n",
    "    return count\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "for course in courses:\n",
    "    observed_keywords = []\n",
    "    observed_2word_phrases = []\n",
    "    observed_3word_phrases = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        original_text = row[course]\n",
    "\n",
    "        keyword_count = count_phrases(original_text, row[f'{course}_keywords'])\n",
    "        two_word_count = count_phrases(original_text, row[f'{course}_2word_phrases'])\n",
    "        three_word_count = count_phrases(original_text, row[f'{course}_3word_phrases'])\n",
    "\n",
    "        observed_keywords.append(keyword_count)\n",
    "        observed_2word_phrases.append(two_word_count)\n",
    "        observed_3word_phrases.append(three_word_count)\n",
    "\n",
    "    total_observed = [\n",
    "        sum(observed_keywords),\n",
    "        sum(observed_2word_phrases),\n",
    "        sum(observed_3word_phrases)\n",
    "    ]\n",
    "\n",
    "    total_count = sum(total_observed)\n",
    "    num_categories = len(total_observed)\n",
    "\n",
    "    expected_counts = [total_count / num_categories] * num_categories\n",
    "\n",
    "    chi2_stat, p_value = chisquare(total_observed, expected_counts)\n",
    "\n",
    "    results[course] = {\n",
    "        'Chi-Squared Statistic': chi2_stat,\n",
    "        'P-value': p_value,\n",
    "        'Significant Difference': p_value < 0.05\n",
    "    }\n",
    "\n",
    "for course, result in results.items():\n",
    "    print(f\"Course: {course}\")\n",
    "    print(f\"  Chi-Squared Statistic: {result['Chi-Squared Statistic']:.4f}\")\n",
    "    print(f\"  P-value: {result['P-value']:.4e}\")\n",
    "    print(f\"  Significant Difference: {'Yes' if result['Significant Difference'] else 'No'}\\n\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def create_check_matrix(df, column_name):\n",
    "    exploded_keyphrases = df.explode(column_name)\n",
    "\n",
    "    presence_matrix = exploded_keyphrases.groupby(['Year', column_name]).size().unstack(fill_value=0)\n",
    "\n",
    "    presence_matrix = (presence_matrix > 0).astype(int)\n",
    "\n",
    "    presence_matrix = presence_matrix.T\n",
    "\n",
    "    return presence_matrix\n",
    "\n",
    "\n",
    "keyword_column = 'Software Testing_keywords'\n",
    "two_word_column = 'Software Testing_2word_phrases'\n",
    "three_word_column = 'Software Testing_3word_phrases'\n",
    "\n",
    "keyword_presence_matrix = create_check_matrix(df, keyword_column)\n",
    "two_word_presence_matrix = create_check_matrix(df, two_word_column)\n",
    "three_word_presence_matrix = create_check_matrix(df, three_word_column)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(12, 18))\n",
    "\n",
    "sns.heatmap(keyword_presence_matrix, annot=True, cmap='binary', fmt='d', ax=axes[0])\n",
    "axes[0].set_title('Keyword Presence Over Years', fontsize=16)\n",
    "axes[0].set_xlabel('Year', fontsize=14)\n",
    "axes[0].set_ylabel('Keywords', fontsize=14)\n",
    "\n",
    "sns.heatmap(two_word_presence_matrix, annot=True, cmap='binary', fmt='d', ax=axes[1])\n",
    "axes[1].set_title('2-Word Phrase Presence Over Years', fontsize=16)\n",
    "axes[1].set_xlabel('Year', fontsize=14)\n",
    "axes[1].set_ylabel('2-Word Phrases', fontsize=14)\n",
    "\n",
    "sns.heatmap(three_word_presence_matrix, annot=True, cmap='binary', fmt='d', ax=axes[2])\n",
    "axes[2].set_title('3-Word Phrase Presence Over Years', fontsize=16)\n",
    "axes[2].set_xlabel('Year', fontsize=14)\n",
    "axes[2].set_ylabel('3-Word Phrases', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "course_columns = df.columns[1:14]\n",
    "relevant_df = df[['Year'] + list(course_columns)]\n",
    "\n",
    "presence_matrix = relevant_df.copy()\n",
    "\n",
    "for col in presence_matrix.columns[1:]:\n",
    "    presence_matrix[col] = presence_matrix[col].apply(lambda x: 0 if x == '-' else 1)\n",
    "\n",
    "presence_matrix.set_index('Year', inplace=True)\n",
    "\n",
    "presence_matrix = presence_matrix.apply(pd.to_numeric)\n",
    "\n",
    "presence_matrix_transposed = presence_matrix.T\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(presence_matrix_transposed, annot=False, cmap='YlGn', cbar=False, fmt='d', linewidths=0.5)\n",
    "plt.title('Course Presence Over Years', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Course', fontsize=14)\n",
    "\n",
    "img_folder = 'img'\n",
    "if not os.path.exists(img_folder):\n",
    "    os.makedirs(img_folder)\n",
    "\n",
    "file_path = os.path.join(img_folder, 'course_presence_heatmap.png')\n",
    "\n",
    "plt.savefig(file_path, bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Heatmap saved to {file_path}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://sbert.net/docs/sentence_transformer/pretrained_models.html#original-models"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "embedded_keywords = [keyword for sublist in df['Embedded Software and Systems_keywords'].dropna().values for keyword in\n",
    "                     sublist if sublist]\n",
    "model_based_keywords = [keyword for sublist in\n",
    "                        df['Model-based Design of Cyber-physical Systems_keywords'].dropna().values for keyword in\n",
    "                        sublist if sublist]\n",
    "\n",
    "all_keywords = embedded_keywords + model_based_keywords\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "keyword_embeddings = model.encode(all_keywords)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(keyword_embeddings)\n",
    "\n",
    "labels = [0] * len(embedded_keywords) + [1] * len(model_based_keywords)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "scatter = plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=labels, cmap='coolwarm', edgecolors='k',\n",
    "                      s=100)\n",
    "\n",
    "for i, keyword in enumerate(all_keywords):\n",
    "    plt.annotate(keyword, (reduced_embeddings[i, 0], reduced_embeddings[i, 1]),\n",
    "                 textcoords=\"offset points\", xytext=(0, 5), ha='center')\n",
    "\n",
    "handles, _ = scatter.legend_elements()\n",
    "plt.legend(handles, [\"Embedded Software and Systems\", \"Model-based Design of Cyber-physical Systems\"], title=\"Course\")\n",
    "\n",
    "plt.title(\"PCA Scatter Plot of Keyword Embeddings by Course\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cos_sim_matrix = cosine_similarity(keyword_embeddings)\n",
    "\n",
    "similarity_threshold = 0.6\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "scatter = plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=labels, cmap='coolwarm', edgecolors='k',\n",
    "                      s=100)\n",
    "\n",
    "for i, keyword in enumerate(all_keywords):\n",
    "    plt.annotate(keyword, (reduced_embeddings[i, 0], reduced_embeddings[i, 1]),\n",
    "                 textcoords=\"offset points\", xytext=(0, 5), ha='center')\n",
    "\n",
    "for i in range(len(all_keywords)):\n",
    "    for j in range(i + 1, len(all_keywords)):\n",
    "        if cos_sim_matrix[i, j] > similarity_threshold:\n",
    "            plt.plot([reduced_embeddings[i, 0], reduced_embeddings[j, 0]],\n",
    "                     [reduced_embeddings[i, 1], reduced_embeddings[j, 1]],\n",
    "                     'k-', lw=0.5, alpha=0.6)\n",
    "\n",
    "handles, _ = scatter.legend_elements()\n",
    "plt.legend(handles, [\"Embedded Software and Systems\", \"Model-based Design of Cyber-physical Systems\"], title=\"Course\")\n",
    "\n",
    "plt.title(\"PCA Scatter Plot of Keyword Embeddings with Cosine Similarity\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.grid(True)\n",
    "\n",
    "file_path = os.path.join(img_folder, 'embedded-cyber-pca.png')\n",
    "\n",
    "plt.savefig(file_path, bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Heatmap saved to {file_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df.to_csv('data/courses_with_30keywords.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ssvt_keywords = [keyword for sublist in df['Software Specification, Verification and Testing_keywords'].dropna().values\n",
    "                 for keyword in sublist if sublist]\n",
    "testing_keywords = [keyword for sublist in df['Software Testing_keywords'].dropna().values for keyword in sublist if\n",
    "                    sublist]\n",
    "\n",
    "all_keywords = ssvt_keywords + testing_keywords\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "keyword_embeddings = model.encode(all_keywords)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(keyword_embeddings)\n",
    "\n",
    "labels = [0] * len(ssvt_keywords) + [1] * len(testing_keywords)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "scatter = plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=labels, cmap='coolwarm', edgecolors='k',\n",
    "                      s=100)\n",
    "\n",
    "for i, keyword in enumerate(all_keywords):\n",
    "    plt.annotate(keyword, (reduced_embeddings[i, 0], reduced_embeddings[i, 1]),\n",
    "                 textcoords=\"offset points\", xytext=(0, 5), ha='center')\n",
    "\n",
    "handles, _ = scatter.legend_elements()\n",
    "plt.legend(handles, [\"Software Specification, Verification and Testing\", \"Software Testing\"], title=\"Course\")\n",
    "\n",
    "plt.title(\"PCA Scatter Plot of Keyword Embeddings by Course\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cos_sim_matrix = cosine_similarity(keyword_embeddings)\n",
    "\n",
    "similarity_threshold = 0.6\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "scatter = plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=labels, cmap='coolwarm', edgecolors='k',\n",
    "                      s=100)\n",
    "\n",
    "for i, keyword in enumerate(all_keywords):\n",
    "    plt.annotate(keyword, (reduced_embeddings[i, 0], reduced_embeddings[i, 1]),\n",
    "                 textcoords=\"offset points\", xytext=(0, 5), ha='center')\n",
    "\n",
    "for i in range(len(all_keywords)):\n",
    "    for j in range(i + 1, len(all_keywords)):\n",
    "        if cos_sim_matrix[i, j] > similarity_threshold:\n",
    "            plt.plot([reduced_embeddings[i, 0], reduced_embeddings[j, 0]],\n",
    "                     [reduced_embeddings[i, 1], reduced_embeddings[j, 1]],\n",
    "                     'k-', lw=0.5, alpha=0.6)\n",
    "\n",
    "handles, _ = scatter.legend_elements()\n",
    "plt.legend(handles, [\"Software Specification, Verification and Testing\", \"Software Testing\"], title=\"Course\")\n",
    "\n",
    "plt.title(\"PCA Scatter Plot of Keyword Embeddings with Cosine Similarity\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.grid(True)\n",
    "\n",
    "file_path = os.path.join(img_folder, 'ssvt-testing-pca.png')\n",
    "\n",
    "plt.savefig(file_path, bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Heatmap saved to {file_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "course_columns = df.columns[1:14]\n",
    "\n",
    "course_contents = {}\n",
    "for course in course_columns:\n",
    "    combined_content = df[course].dropna().str.cat(sep=' ')\n",
    "    course_contents[course] = combined_content\n",
    "\n",
    "courses_df = pd.DataFrame(list(course_contents.items()), columns=['Course', 'Content'])\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "course_embeddings = model.encode(courses_df['Content'].tolist())\n",
    "\n",
    "similarity_matrix = cosine_similarity(course_embeddings)\n",
    "\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=courses_df['Course'], columns=courses_df['Course'])\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "sns.heatmap(similarity_df, annot=True, cmap='coolwarm', fmt=\".2f\", square=True, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Course Semantic Similarity Heatmap')\n",
    "plt.xlabel('Courses')\n",
    "plt.ylabel('Courses')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks()\n",
    "\n",
    "file_path = os.path.join(img_folder, 'similarity-courses.png')\n",
    "\n",
    "plt.savefig(file_path, bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Heatmap saved to {file_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "c_df = pd.read_csv('data/courses.csv')\n",
    "c_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "c_df['combined'] = c_df.iloc[:, 1:].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "c_df.drop(c_df.columns[1:-1], axis=1, inplace=True)\n",
    "c_df.head()\n",
    "\n",
    "c_df.to_csv('data/courses_combined.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "year_embeddings = model.encode(c_df['combined'].tolist())\n",
    "\n",
    "similarity_matrix = cosine_similarity(year_embeddings)\n",
    "\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=c_df['Year'], columns=c_df['Year'])\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "sns.heatmap(similarity_df, annot=True, cmap='coolwarm', fmt=\".2f\", square=True, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Yearly Semantic Similarity Heatmap')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Year')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks()\n",
    "plt.tight_layout()\n",
    "\n",
    "file_path = os.path.join(img_folder, 'similarity-years.png')\n",
    "\n",
    "plt.savefig(file_path, bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Heatmap saved to {file_path}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "learning_outcomes = [\n",
    "    \"Graduates are familiar with the most relevant theories, methods and techniques in the domain of Software Engineering.\",\n",
    "    \"Graduates have the necessary background knowledge to familiarise themselves with novel methods and techniques for life-long learning.\",\n",
    "    \"Graduates can successfully apply theory in practice in order to find innovative solutions for both general and domain-specific software engineering problems.\",\n",
    "    \"Graduates can make valuable contributions to complex software engineering projects through the independent and critical application of academic knowledge and skills.\",\n",
    "    \"Graduates have sufficient technical understanding and intellectual capacity to play, after some years of practical experience, a managerial or advisory role in software engineering.\",\n",
    "    \"Graduates can clearly report their findings, both in oral and in written form, and can explain problems at an audience-focused level of abstraction.\",\n",
    "    \"Graduates have research skills at the academic level and are capable to autonomously perform research in the domain of software engineering.\",\n",
    "    \"Graduates understand why user needs are difficult to express, capture and understand and graduates are familiar with best practices in requirements engineering as well as their shortcomings.\",\n",
    "    \"Graduates are able to produce formal specifications of modest-sized samples of software and to use them for the generation of meaningful tests; they understand the essential concepts of software verification.\",\n",
    "    \"Graduates master the methods and techniques for analysing existing software systems and their evolution in the context of changing requirements.\",\n",
    "    \"Graduates are familiar with the characteristics of software for embedded systems and know how to accommodate these characteristics in the software design and development phases.\",\n",
    "    \"Graduates understand why big software projects are prone to failure and are familiar with software engineering process models, their situation-awareness and their general shortcomings.\",\n",
    "    \"Graduates are familiar with the concept of DevOps and their benefits for organisational IT infrastructure and services management; they understand how to build cloud-based applications and how to use cloud automation tools across a wide range of application scenarios.\"\n",
    "]\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "course_columns = df.columns[1:14]\n",
    "\n",
    "course_contents = {}\n",
    "for course in course_columns:\n",
    "    combined_content = df[course].dropna().str.cat(sep=' ')\n",
    "    course_contents[course] = combined_content\n",
    "\n",
    "courses_df = pd.DataFrame(list(course_contents.items()), columns=['Course', 'Content'])\n",
    "\n",
    "course_embeddings = model.encode(courses_df['Content'].tolist())\n",
    "\n",
    "outcome_embeddings = model.encode(learning_outcomes)\n",
    "\n",
    "similarity_scores = cosine_similarity(course_embeddings, outcome_embeddings)\n",
    "\n",
    "similarity_df = pd.DataFrame(similarity_scores, index=courses_df['Course'],\n",
    "                             columns=[f'Outcome {i + 1}' for i in range(len(learning_outcomes))])\n",
    "\n",
    "print(\"Similarity Scores between Courses and Learning Outcomes:\")\n",
    "print(similarity_df)\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "sns.heatmap(similarity_df, annot=True, cmap='coolwarm', fmt=\".2f\", square=True, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Course-Level Semantic Similarity to Learning Outcomes')\n",
    "plt.xlabel('Learning Outcomes')\n",
    "plt.ylabel('Courses')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks()\n",
    "\n",
    "img_folder = 'img'\n",
    "file_path = os.path.join(img_folder, 'similarity-courses-to-outcomes-individual.png')\n",
    "\n",
    "plt.savefig(file_path, bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Heatmap saved to {file_path}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
